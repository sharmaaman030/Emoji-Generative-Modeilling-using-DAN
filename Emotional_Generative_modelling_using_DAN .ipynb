{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Emotional_Generative_modelling_using_DAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGUU3JHgXLrC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "#nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "#!pip install emoji\n",
        "import emoji as emoji\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41qv81lmXLrQ"
      },
      "source": [
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2JegODbXLrQ"
      },
      "source": [
        "def run():\n",
        "  train_X = pd.read_csv('emojify_train_x.csv',header=None)\n",
        "  test_X = pd.read_csv('emojiy_test_x.csv',header=None)\n",
        "\n",
        "  train_Y = pd.read_csv('Emojify_Y_train.csv',header=None)\n",
        "\n",
        "  test_Y = pd.read_csv('emojiy_y_test.csv',header=None)\n",
        "\n",
        "  frames = [train_X , test_X]\n",
        "  X = pd.concat(frames)\n",
        "  frames = [train_Y , test_Y]\n",
        "  Y = pd.concat(frames)\n",
        "  #X.shape\n",
        "  #Y.shape\n",
        "\n",
        "  import re as s\n",
        "  def clean(train):\n",
        "    List = train.iloc[:,0].tolist()\n",
        "    Regex = str.maketrans(\"\",\"\",\"'\")\n",
        "    word = [s.translate(Regex) for s in List]\n",
        "    tokenized_sent = []\n",
        "    for s in word:\n",
        "      tokenized_sent.append(word_tokenize(s.lower())) \n",
        "    return word , tokenized_sent\n",
        "\n",
        "  trained_list , trained_and_tokened_list = clean(X)\n",
        "\n",
        "  emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
        "                      \"1\": \":baseball:\",\n",
        "                      \"2\": \":beaming_face_with_smiling_eyes:\",\n",
        "                      \"3\": \":downcast_face_with_sweat:\",\n",
        "                      \"4\": \":fork_and_knife:\",\n",
        "                    }\n",
        "\n",
        "\n",
        "  module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
        "  model_e = hub.load(module_url)\n",
        "  #print (\"module %s loaded\" % module_url)\n",
        "\n",
        "  sentence_embeddings = model_e(trained_list)\n",
        "  category = Y.iloc[:,0].tolist()\n",
        "  category_ohe = pd.get_dummies(category)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(sentence_embeddings.numpy(), category_ohe, test_size=0.33, random_state=42)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(64, input_dim=512, activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(5, activation='sigmoid'))\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['acc'])\n",
        "  model.fit(X_train,y_train,epochs=40,shuffle=True,validation_split=0.1)\n",
        "\n",
        "\n",
        "  def getEmoji(sentence):\n",
        "    query = []\n",
        "    query.append(sentence)\n",
        "    inp = model_e(query)\n",
        "    out =  model.predict_classes(inp)\n",
        "    print('Statement is :  '+query[0])\n",
        "    print('Classification Result is :  '+emoji.emojize(emoji_dictionary[str(out[0])]))\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxLCUshv8EO9"
      },
      "source": [
        "#emoji.EMOJI_ALIAS_UNICODE\n",
        "#model.evaluate(X_test,y_test)\n",
        "# for e in emoji_dictionary.values():\n",
        "#     print(emoji.emojize(e))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuEkGgwtl-xm",
        "outputId": "934ba4f2-c48e-4d3b-f91e-8aa22cd4601c"
      },
      "source": [
        "run()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f9b514d8560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f9b514d8560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f9b5061ec20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f9b5061ec20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "4/4 [==============================] - 1s 87ms/step - loss: 1.6094 - acc: 0.1772 - val_loss: 1.5646 - val_acc: 0.6154\n",
            "Epoch 2/40\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.5617 - acc: 0.7001 - val_loss: 1.5098 - val_acc: 0.8462\n",
            "Epoch 3/40\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.5140 - acc: 0.7859 - val_loss: 1.4398 - val_acc: 0.8462\n",
            "Epoch 4/40\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.4615 - acc: 0.7421 - val_loss: 1.3555 - val_acc: 0.8462\n",
            "Epoch 5/40\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.3867 - acc: 0.7993 - val_loss: 1.2513 - val_acc: 0.8462\n",
            "Epoch 6/40\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.3171 - acc: 0.7653 - val_loss: 1.1320 - val_acc: 0.8462\n",
            "Epoch 7/40\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.2032 - acc: 0.8000 - val_loss: 0.9986 - val_acc: 0.8462\n",
            "Epoch 8/40\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.0882 - acc: 0.8368 - val_loss: 0.8734 - val_acc: 0.9231\n",
            "Epoch 9/40\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.9461 - acc: 0.8750 - val_loss: 0.7441 - val_acc: 0.9231\n",
            "Epoch 10/40\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.8182 - acc: 0.9065 - val_loss: 0.6316 - val_acc: 0.9231\n",
            "Epoch 11/40\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.6699 - acc: 0.9329 - val_loss: 0.5345 - val_acc: 0.9231\n",
            "Epoch 12/40\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.5618 - acc: 0.9463 - val_loss: 0.4478 - val_acc: 0.9231\n",
            "Epoch 13/40\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4514 - acc: 0.9576 - val_loss: 0.3743 - val_acc: 0.9231\n",
            "Epoch 14/40\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3410 - acc: 0.9768 - val_loss: 0.3079 - val_acc: 0.9231\n",
            "Epoch 15/40\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.2567 - acc: 1.0000 - val_loss: 0.2604 - val_acc: 0.9231\n",
            "Epoch 16/40\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.2129 - acc: 1.0000 - val_loss: 0.2230 - val_acc: 0.9231\n",
            "Epoch 17/40\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.1699 - acc: 1.0000 - val_loss: 0.1990 - val_acc: 0.9231\n",
            "Epoch 18/40\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.1241 - acc: 1.0000 - val_loss: 0.1780 - val_acc: 0.9231\n",
            "Epoch 19/40\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0982 - acc: 1.0000 - val_loss: 0.1645 - val_acc: 0.9231\n",
            "Epoch 20/40\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0795 - acc: 1.0000 - val_loss: 0.1524 - val_acc: 0.9231\n",
            "Epoch 21/40\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0594 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9231\n",
            "Epoch 22/40\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0456 - acc: 1.0000 - val_loss: 0.1367 - val_acc: 0.9231\n",
            "Epoch 23/40\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0422 - acc: 1.0000 - val_loss: 0.1315 - val_acc: 0.9231\n",
            "Epoch 24/40\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0365 - acc: 1.0000 - val_loss: 0.1260 - val_acc: 0.9231\n",
            "Epoch 25/40\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0319 - acc: 1.0000 - val_loss: 0.1229 - val_acc: 0.9231\n",
            "Epoch 26/40\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.1209 - val_acc: 0.9231\n",
            "Epoch 27/40\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.1176 - val_acc: 0.9231\n",
            "Epoch 28/40\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.1140 - val_acc: 0.9231\n",
            "Epoch 29/40\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9231\n",
            "Epoch 30/40\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.1076 - val_acc: 0.9231\n",
            "Epoch 31/40\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9231\n",
            "Epoch 32/40\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9231\n",
            "Epoch 33/40\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.1059 - val_acc: 0.9231\n",
            "Epoch 34/40\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9231\n",
            "Epoch 35/40\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1050 - val_acc: 0.9231\n",
            "Epoch 36/40\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.1039 - val_acc: 0.9231\n",
            "Epoch 37/40\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9231\n",
            "Epoch 38/40\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.1016 - val_acc: 0.9231\n",
            "Epoch 39/40\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1009 - val_acc: 0.9231\n",
            "Epoch 40/40\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9231\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function recreate_function.<locals>.restored_function_body at 0x7f9b506234d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 12 calls to <function recreate_function.<locals>.restored_function_body at 0x7f9b506234d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prtXZRmsmV05",
        "outputId": "2882e07b-ffaa-4ae7-80e1-ba88e129ee8b"
      },
      "source": [
        "sentence = input()\n",
        "getEmoji(sentence)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He is crying\n",
            "Statement is :  He is crying\n",
            "Classification Result is :  ðŸ˜“\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHvGQi3JnOW3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}