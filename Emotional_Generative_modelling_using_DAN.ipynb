{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Emotional Generative modelling using DAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGUU3JHgXLrC"
      },
      "source": [
        " import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1jhLSl7pW9v",
        "outputId": "064d9b5b-25aa-4ffd-b339-fb7550ebef65"
      },
      "source": [
        "\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W67tKju5XLrN",
        "outputId": "23622c94-40a5-42ab-9241-fa535861ccb8"
      },
      "source": [
        "!pip install emoji\n",
        "import emoji as emoji\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/fa/b3368f41b95a286f8d300e323449ab4e86b85334c2e0b477e94422b8ed0f/emoji-1.2.0-py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.1MB/s \n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsJOM_ZFXLrP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41qv81lmXLrQ"
      },
      "source": [
        "train_X = pd.read_csv('emojify_train_x.csv',header=None)\n",
        "test_X = pd.read_csv('emojiy_test_x.csv',header=None)\n",
        "\n",
        "train_Y = pd.read_csv('Emojify_Y_train.csv',header=None)\n",
        "test_Y = pd.read_csv('emojiy_y_test.csv',header=None)\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2JegODbXLrQ",
        "outputId": "ba4fc737-d301-4d24-856a-9149efb57c82"
      },
      "source": [
        "frames = [train_X , test_X]\n",
        "X = pd.concat(frames)\n",
        "X.shape"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(188, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW8abFRUdllf",
        "outputId": "11fdb54d-437a-4a1f-8b1c-c1cb364d9653"
      },
      "source": [
        "frames = [train_Y , test_Y]\n",
        "Y = pd.concat(frames)\n",
        "Y.shape"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(188, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U0Zn0JLkJ2j"
      },
      "source": [
        "import re as s\n",
        "def sudharo(train):\n",
        "  sex = train.iloc[:,0].tolist()\n",
        "  makeout = str.maketrans(\"\",\"\",\"'\")\n",
        "  dick1 = [s.translate(makeout) for s in sex]\n",
        "  tokenized_sent = []\n",
        "  for s in dick1:\n",
        "    tokenized_sent.append(word_tokenize(s.lower())) \n",
        "  return dick1 , tokenized_sent\n",
        "\n",
        "\n",
        "trained_list , trained_and_tokened_list = sudharo(X)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4117-84plQDz",
        "outputId": "775e7328-1f6f-4566-ede2-1d2abf95477e"
      },
      "source": [
        "trained_list[0] "
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'never talk to me again '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RMYOCfYrTcW",
        "outputId": "0b306998-43d0-4069-a065-f9987d1c67fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
        "model_e = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)\n",
        "\n",
        "sentence_embeddings = model_e(trained_list)\n",
        "'''query = \"I had pizza and pasta\"\n",
        "query_vec = model([query])[0]\n",
        "\n",
        "for sent in trained_list:\n",
        "  sim = cosine(query_vec, model([sent])[0])\n",
        "  print(\"Sentence = \", sent, \"; similarity = \", sim)\n",
        "'''"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:9 out of the last 142 calls to <function recreate_function.<locals>.restored_function_body at 0x7f75a13565f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:9 out of the last 142 calls to <function recreate_function.<locals>.restored_function_body at 0x7f75a13565f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n",
            "WARNING:tensorflow:10 out of the last 143 calls to <function recreate_function.<locals>.restored_function_body at 0x7f759d0a23b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:10 out of the last 143 calls to <function recreate_function.<locals>.restored_function_body at 0x7f759d0a23b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'query = \"I had pizza and pasta\"\\nquery_vec = model([query])[0]\\n\\nfor sent in trained_list:\\n  sim = cosine(query_vec, model([sent])[0])\\n  print(\"Sentence = \", sent, \"; similarity = \", sim)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VON0EKVzvf7X"
      },
      "source": [
        "category = test.iloc[:,0].tolist()\n",
        "category_ohe = pd.get_dummies(category)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHKZbca_5RTt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentence_embeddings.numpy(), category_ohe, test_size=0.33, random_state=42)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPX5jGSiXLrb",
        "outputId": "f4368298-b1d0-45cd-8126-acf092ff88f9"
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Sequential\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=512, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['acc'])\n",
        "model.fit(X_train,y_train,epochs=40,shuffle=True,validation_split=0.1)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "3/3 [==============================] - 1s 123ms/step - loss: 1.6069 - acc: 0.2043 - val_loss: 1.5982 - val_acc: 0.2222\n",
            "Epoch 2/40\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.5753 - acc: 0.5986 - val_loss: 1.5719 - val_acc: 0.5556\n",
            "Epoch 3/40\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5458 - acc: 0.7235 - val_loss: 1.5391 - val_acc: 0.5556\n",
            "Epoch 4/40\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5061 - acc: 0.7562 - val_loss: 1.5009 - val_acc: 0.5556\n",
            "Epoch 5/40\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.4684 - acc: 0.7084 - val_loss: 1.4542 - val_acc: 0.6667\n",
            "Epoch 6/40\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4131 - acc: 0.7123 - val_loss: 1.3981 - val_acc: 0.7778\n",
            "Epoch 7/40\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3536 - acc: 0.7499 - val_loss: 1.3347 - val_acc: 0.7778\n",
            "Epoch 8/40\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.2852 - acc: 0.7406 - val_loss: 1.2602 - val_acc: 0.7778\n",
            "Epoch 9/40\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2056 - acc: 0.7611 - val_loss: 1.1780 - val_acc: 0.7778\n",
            "Epoch 10/40\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1029 - acc: 0.8001 - val_loss: 1.0908 - val_acc: 0.7778\n",
            "Epoch 11/40\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0461 - acc: 0.7825 - val_loss: 0.9933 - val_acc: 0.7778\n",
            "Epoch 12/40\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.9011 - acc: 0.8694 - val_loss: 0.8889 - val_acc: 0.8889\n",
            "Epoch 13/40\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.8183 - acc: 0.9010 - val_loss: 0.7798 - val_acc: 0.8889\n",
            "Epoch 14/40\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.6817 - acc: 0.9615 - val_loss: 0.6719 - val_acc: 0.8889\n",
            "Epoch 15/40\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6057 - acc: 0.9717 - val_loss: 0.5715 - val_acc: 0.8889\n",
            "Epoch 16/40\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4716 - acc: 1.0000 - val_loss: 0.4815 - val_acc: 1.0000\n",
            "Epoch 17/40\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.3907 - acc: 1.0000 - val_loss: 0.4051 - val_acc: 1.0000\n",
            "Epoch 18/40\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.3284 - acc: 1.0000 - val_loss: 0.3394 - val_acc: 1.0000\n",
            "Epoch 19/40\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.2458 - acc: 1.0000 - val_loss: 0.2873 - val_acc: 1.0000\n",
            "Epoch 20/40\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1905 - acc: 1.0000 - val_loss: 0.2451 - val_acc: 1.0000\n",
            "Epoch 21/40\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1470 - acc: 1.0000 - val_loss: 0.2086 - val_acc: 1.0000\n",
            "Epoch 22/40\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.1125 - acc: 1.0000 - val_loss: 0.1792 - val_acc: 1.0000\n",
            "Epoch 23/40\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0889 - acc: 1.0000 - val_loss: 0.1544 - val_acc: 1.0000\n",
            "Epoch 24/40\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0701 - acc: 1.0000 - val_loss: 0.1323 - val_acc: 1.0000\n",
            "Epoch 25/40\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0504 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 1.0000\n",
            "Epoch 26/40\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0447 - acc: 1.0000 - val_loss: 0.1029 - val_acc: 1.0000\n",
            "Epoch 27/40\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0367 - acc: 1.0000 - val_loss: 0.0932 - val_acc: 1.0000\n",
            "Epoch 28/40\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 1.0000\n",
            "Epoch 29/40\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0258 - acc: 1.0000 - val_loss: 0.0791 - val_acc: 1.0000\n",
            "Epoch 30/40\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.0736 - val_acc: 1.0000\n",
            "Epoch 31/40\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.0691 - val_acc: 1.0000\n",
            "Epoch 32/40\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 1.0000\n",
            "Epoch 33/40\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0614 - val_acc: 1.0000\n",
            "Epoch 34/40\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0581 - val_acc: 1.0000\n",
            "Epoch 35/40\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0551 - val_acc: 1.0000\n",
            "Epoch 36/40\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0525 - val_acc: 1.0000\n",
            "Epoch 37/40\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 1.0000\n",
            "Epoch 38/40\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0484 - val_acc: 1.0000\n",
            "Epoch 39/40\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0467 - val_acc: 1.0000\n",
            "Epoch 40/40\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0450 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f759bc936d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNYSFjf9XLrc",
        "outputId": "bc5073d2-065a-4150-b8b7-4152b7a1709f"
      },
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4060 - acc: 0.8636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40597522258758545, 0.8636363744735718]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S1qHt_y99sX",
        "outputId": "6cc736eb-757c-4021-ea7c-03f8e216551f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxLCUshv8EO9"
      },
      "source": [
        "import emoji as emoji\n",
        "#emoji.EMOJI_ALIAS_UNICODE\n",
        "\n",
        "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
        "                    \"1\": \":baseball:\",\n",
        "                    \"2\": \":beaming_face_with_smiling_eyes:\",\n",
        "                    \"3\": \":downcast_face_with_sweat:\",\n",
        "                    \"4\": \":fork_and_knife:\",\n",
        "                   }\n"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4yZT1xb-mdc",
        "outputId": "02b1adcf-0057-4a9e-f9df-831c218db1f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for e in emoji_dictionary.values():\n",
        "    print(emoji.emojize(e))"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "❤️\n",
            "⚾\n",
            "😁\n",
            "😓\n",
            "🍴\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22A4cWW5-t20",
        "outputId": "9e54033b-28aa-4f9c-8c57-f78492947a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "emoji.emojize(emoji_dictionary[str(1)])"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'⚾'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFgggM447e3y",
        "outputId": "94a1938b-6c90-4991-d4d5-2ebcc5d1a8e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "query = ['Im sad']\n",
        "inp = model_e(query)\n",
        "out =  model.predict_classes(inp)\n",
        "print('Statement is :  '+query[0])\n",
        "print('Classification Result is :  '+emoji.emojize(emoji_dictionary[str(out[0])]))\n",
        "\n"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statement is :  Im sad\n",
            "Classification Result is :  😓\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seWUMc2y-TgK"
      },
      "source": [
        ""
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZqk6Hpu-JZE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}